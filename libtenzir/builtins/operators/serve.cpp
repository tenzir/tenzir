//    _   _____   __________
//   | | / / _ | / __/_  __/     Visibility
//   | |/ / __ |_\ \  / /          Across
//   |___/_/ |_/___/ /_/       Space and Time
//
// SPDX-FileCopyrightText: (c) 2023 The Tenzir Contributors
// SPDX-License-Identifier: BSD-3-Clause

// ARCHITECTURE
//
// The serve builtin contains three parts, namely the serve-manager component,
// the serve operator, and the /serve endpoint.
//
// SERVE OPERATOR
//
// The serve operator is an event sink that exposes the events it receives
// incrementally through a REST API.
//
// SERVE ENDPOINT
//
// The /serve endpoint allows for fetching events from a pipeline that ended in
// the serve operator incrementally.
//
// SERVE-MANAGER COMPONENT
//
// The serve-manager component is invisible to the user. It is responsible for
// bridging between the serve operator and the /serve endpoint, observing when
// the operator is done, throttling the operator when events are being requested
// too slowly, and managing request limits and timeouts.
//
// KNOWN ISSUES & LIMITATIONS
//
// The serve operator must currently run detached because it uses blocking
// communication for throttling. This would not be required if the operator API
// used an awaitable coroutine like an async generator. We should revisit this
// once the operator API supports awaiting non-blocking requests.
//
// The web is a lossy placeâ€”which is why the serve-manager caches its last
// result set and the last continuation token. To also be able to cache the last
// result set, we delay the removal of the managed serve operators in the
// serve-manager by 1 minute.
//
// Technically, the serve-manager should not be needed. However, the current
// architecture of the web plugin makes it so that the REST handler actor is not
// implicitly a component actor, and as such may run outside of the node or even
// multiple times. We should revisit this in the future.

#include <tenzir/actors.hpp>
#include <tenzir/argument_parser.hpp>
#include <tenzir/arrow_table_slice.hpp>
#include <tenzir/concept/convertible/to.hpp>
#include <tenzir/concept/parseable/numeric.hpp>
#include <tenzir/concept/parseable/tenzir/expression.hpp>
#include <tenzir/concept/parseable/tenzir/pipeline.hpp>
#include <tenzir/concept/parseable/to.hpp>
#include <tenzir/concept/printable/tenzir/json.hpp>
#include <tenzir/detail/weak_run_delayed.hpp>
#include <tenzir/node.hpp>
#include <tenzir/pipeline.hpp>
#include <tenzir/plugin.hpp>
#include <tenzir/query_context.hpp>
#include <tenzir/query_cursor.hpp>
#include <tenzir/series_builder.hpp>
#include <tenzir/status.hpp>
#include <tenzir/table_slice.hpp>
#include <tenzir/tql2/plugin.hpp>

#include <arrow/record_batch.h>
#include <caf/actor_addr.hpp>
#include <caf/actor_registry.hpp>
#include <caf/scoped_actor.hpp>
#include <caf/stateful_actor.hpp>
#include <caf/typed_event_based_actor.hpp>

#include <sstream>

namespace tenzir::plugins::serve {

TENZIR_ENUM(serve_state, running, completed, failed);

namespace {

constexpr auto SERVE_ENDPOINT_ID = 0;

constexpr auto SPEC_V0 = R"_(
/serve:
  post:
    summary: Return data from a pipeline
    description: "Returns events from an existing pipeline. The pipeline definition must include a serve operator. By default, the endpoint performs long polling (`timeout: 5s`) and returns events as soon as they are available (`min_events: 1`)."
    requestBody:
      description: Body for the serve endpoint
      required: true
      content:
        application/json:
          schema:
            type: object
            required: [serve_id]
            properties:
              serve_id:
                type: string
                example: "query1"
                description: The id that was passed to the serve operator.
              continuation_token:
                type: string
                example: "340ce2j"
                description: The continuation token that was returned with the last response. For the initial request this is null.
              max_events:
                type: integer
                example: 1024
                default: 1024
                description: The maximum number of events returned.
              min_events:
                type: integer
                example: 1
                default: 1
                description: Wait for this number of events before returning.
              timeout:
                type: string
                example: "200ms"
                default: "5s"
                description: The maximum amount of time spent on the request. Hitting the timeout is not an error. The timeout must not be greater than 10 seconds.
              schema:
                type: string
                example: "exact"
                default: "legacy"
                description: The output format in which schemas are represented. Must be one of "legacy", "exact", or "never". Use "exact" to switch to a type representation matching Tenzir's type system exactly, and "never" to omit schema schema definitions from the output entirely.
    responses:
      200:
        description: Success.
        content:
          application/json:
            schema:
              type: object
              properties:
                next_continuation_token:
                  type: string
                  description: A token to access the next pipeline data batch, null if the pipeline is completed.
                  example: "340ce2j"
                state:
                  type: string
                  description: The state of the corresponding pipeline at the time of the request. One of `running`, `completed`, or `failed`.
                  example: "running"
                schemas:
                  type: array
                  items:
                    type: object
                    properties:
                      schema_id:
                        type: string
                        description: The unique schema identifier.
                      definition:
                        type: object
                        description: The schema definition in JSON format.
                  description: The schemas that the served events are based on.
                  example:
                  - schema_id: c631d301e4b18f4
                    definition:
                    - name: tenzir.summarize
                      kind: record
                      type: tenzir.summarize
                      attributes: {}
                      path: []
                      fields:
                      - name: severity
                        kind: string
                        type: string
                        attributes: {}
                        path:
                        - 0
                        fields: []
                      - name: pipeline_id
                        kind: string
                        type: string
                        attributes: {}
                        path:
                        - 1
                        fields: []
                events:
                  type: array
                  items:
                    type: object
                    properties:
                      schema_id:
                        type: string
                        description: The unique schema identifier.
                      data:
                        type: object
                        description: The actual served data in JSON format.
                  description: The served events.
                  example:
                  - schema_id: c631d301e4b18f4
                    data:
                      timestamp: "2023-04-26T12:00:00Z"
                      schema: "zeek.conn"
                      schema_id: "ab2371bas235f1"
                      events: 50
                  - schema_id: c631d301e4b18f4
                    data:
                      timestamp: "2023-04-26T12:05:00Z"
                      schema: "suricata.dns"
                      schema_id: "cd4771bas235f1"
                      events: 50
      400:
        description: Invalid arguments.
        content:
          application/json:
            schema:
              type: object
              required: [error]
              properties:
                error:
                  type: string
                  example: "Invalid arguments"
                  description: The error message.
    )_";

// -- serve manager -----------------------------------------------------------

using serve_manager_actor = typed_actor_fwd<
  // Register a new serve operator.
  auto(atom::start, std::string serve_id, uint64_t buffer_size)
    ->caf::result<void>,
  // Deregister a serve operator, waiting until it completed.
  auto(atom::stop, std::string serve_id)->caf::result<void>,
  // Put additional slices into the buffer for the given access token.
  auto(atom::put, std::string serve_id, table_slice)->caf::result<void>,
  // Get slices from the buffer for the given access token, returning the next
  // access token and the desired number of events.
  auto(atom::get, std::string serve_id, std::string continuation_token,
       uint64_t min_events, duration timeout, uint64_t max_events)
    ->caf::result<std::tuple<std::string, std::vector<table_slice>>>>
  // Conform to the protocol of the COMPONENT PLUGIN actor interface.
  ::extend_with<component_plugin_actor>::unwrap;

struct request_limits {
  uint64_t max_events = defaults::api::serve::max_events;
  uint64_t min_events = defaults::api::serve::min_events;
  duration timeout = defaults::api::serve::timeout;
};

TENZIR_ENUM(schema, legacy, exact, never);

struct serve_request {
  std::string serve_id = {};
  std::string continuation_token = {};
  enum schema schema = schema::legacy;
  request_limits limits = {};
};

/// A single serve operator as observed by the serve-manager.
struct managed_serve_operator {
  /// The actor address of the execution node of the serve operator; stored for
  /// tracking purposes.
  caf::actor_addr source = {};

  /// The serve ID and next expected continuation token of the operator.
  std::string serve_id = {};
  std::string continuation_token = {};

  /// The web is a naturally lossy place, so we cache the last response in case
  /// it didn't get delivered so the client can retry.
  bool done = {};
  std::string last_continuation_token = {};
  std::vector<table_slice> last_results = {};

  /// The buffered table slice, and the configured buffer size and the number of
  /// currently requested events (may exceed the buffer size).
  std::vector<table_slice> buffer = {};
  uint64_t buffer_size = defaults::api::serve::max_events;
  uint64_t requested = {};
  uint64_t min_events = {};

  /// The number of delivered results. Tracked only for the status output and
  /// not used otherwise.
  uint64_t delivered = {};

  /// Various handles for interfacing with the endpoint and the operator, and
  /// throttling the pipeline leading into the operator.
  caf::disposable delayed_attempt = {};
  caf::typed_response_promise<void> put_rp = {};
  caf::typed_response_promise<void> stop_rp = {};
  std::vector<caf::typed_response_promise<
    std::tuple<std::string, std::vector<table_slice>>>>
    get_rps = {};

  /// Attempt to deliver up to the number of requested results.
  /// @param force_underful Return underful result sets instead of failing when
  /// not enough results are buffered.
  /// @returns Whether the results were delivered.
  auto try_deliver_results(bool force_underful) -> bool {
    TENZIR_ASSERT(not get_rps.empty());
    // If we throttled the serve operator, then we can continue its operation
    // again if we have less events buffered than desired.
    if (put_rp.pending() and rows(buffer) < std::max(buffer_size, requested)) {
      put_rp.deliver();
    }
    // Avoid delivering too early, i.e., when we don't yet have enough events.
    const auto return_underful = stop_rp.pending() or force_underful;
    if (not return_underful and rows(buffer) < min_events
        and rows(buffer) < requested) {
      return false;
    }
    // Cut the results buffer.
    auto results = std::vector<table_slice>{};
    std::tie(results, buffer) = split(buffer, requested);
    delivered += rows(results);
    // Clear the delayed attempt and the continuation token.
    delayed_attempt.dispose();
    requested = 0;
    TENZIR_DEBUG("clearing continuation token");
    last_continuation_token = std::exchange(continuation_token, {});
    last_results = results;
    if (stop_rp.pending() and buffer.empty()) {
      TENZIR_ASSERT(not put_rp.pending());
      TENZIR_DEBUG("serve for id {} is done", escape_operator_arg(serve_id));
      continuation_token.clear();
      for (auto&& get_rp : std::exchange(get_rps, {})) {
        TENZIR_ASSERT(get_rp.pending());
        get_rp.deliver(std::make_tuple(std::string{}, results));
      }
      stop_rp.deliver();
      return true;
    }
    // If we throttled the serve operator, then we can continue its operation
    // again if we have less events buffered than desired.
    if (put_rp.pending() and rows(buffer) < buffer_size) {
      put_rp.deliver();
    }
    continuation_token = fmt::to_string(uuid::random());
    TENZIR_DEBUG("serve for id {} is now available with continuation token {}",
                 escape_operator_arg(serve_id), continuation_token);
    for (auto&& get_rp : std::exchange(get_rps, {})) {
      TENZIR_ASSERT(get_rp.pending());
      get_rp.deliver(std::make_tuple(continuation_token, results));
    }
    return true;
  }
};

struct serve_manager_state {
  static constexpr auto name = "serve-manager";

  serve_manager_actor::pointer self = {};

  /// The serve operators currently observed by the serve-manager.
  std::vector<managed_serve_operator> ops = {};

  /// A list of previously known serve ids that were expired and their
  /// corresponding error messages. This exists only for returning better error
  /// messages to the user.
  std::unordered_map<std::string, caf::error> expired_ids = {};

  auto handle_down_msg(const caf::actor_addr& source, const caf::error& err)
    -> void {
    const auto found = std::ranges::find_if(ops, [&](const auto& op) {
      return op.source == source;
    });
    TENZIR_ASSERT(found != ops.end());
    if (not found->continuation_token.empty()) {
      TENZIR_DEBUG("{} received premature DOWN for serve id {} with "
                   "continuation "
                   "token {}",
                   *self, found->serve_id, found->continuation_token);
    }
    // We delay the actual removal because we support fetching the
    // last set of events again by reusing the last continuation token.
    found->done = true;
    auto delete_serve = [this, source, err]() {
      const auto found = std::ranges::find_if(ops, [&](const auto& op) {
        return op.source == source;
      });
      if (found != ops.end()) {
        expired_ids.emplace(found->serve_id, err);
        if (not found->get_rps.empty()) {
          found->delayed_attempt.dispose();
          for (auto&& get_rp : std::exchange(found->get_rps, {})) {
            get_rp.deliver(err);
          }
        }
        ops.erase(found);
      }
    };
    if (err) {
      delete_serve();
      return;
    }
    detail::weak_run_delayed(self, defaults::api::serve::retention_time,
                             delete_serve);
  }

  auto start(std::string serve_id, uint64_t buffer_size) -> caf::result<void> {
    const auto found = std::ranges::find_if(ops, [&](const auto& op) {
      return op.serve_id == serve_id;
    });
    if (found != ops.end()) {
      if (not found->done) {
        return caf::make_error(
          ec::invalid_argument,
          fmt::format("{} received duplicate serve id {}", *self,
                      escape_operator_arg(found->serve_id)));
      }
      ops.erase(found);
    }
    const auto sender = caf::actor_cast<caf::actor>(self->current_sender());
    TENZIR_ASSERT(sender);
    const auto addr = sender->address();
    ops.push_back({
      .source = addr,
      .serve_id = serve_id,
      .continuation_token = "",
      .buffer_size = buffer_size,
    });
    self->monitor(sender, [this, addr](const caf::error& err) {
      handle_down_msg(addr, err);
    });
    return {};
  }

  auto stop(std::string serve_id) -> caf::result<void> {
    const auto found
      = std::find_if(ops.begin(), ops.end(), [&](const auto& op) {
          return op.serve_id == serve_id;
        });
    if (found == ops.end()) {
      return caf::make_error(ec::invalid_argument,
                             fmt::format("{} received request to despawn for "
                                         "unknown serve id {}",
                                         *self, escape_operator_arg(serve_id)));
    }
    if (found->stop_rp.pending()) {
      return caf::make_error(ec::logic_error,
                             fmt::format("{} received duplicate request to "
                                         "despawn for serve id {}",
                                         *self, escape_operator_arg(serve_id)));
    }
    found->stop_rp = self->make_response_promise<void>();
    return found->stop_rp;
  }

  auto put(std::string serve_id, table_slice slice) -> caf::result<void> {
    const auto found
      = std::find_if(ops.begin(), ops.end(), [&](const auto& op) {
          return op.serve_id == serve_id;
        });
    if (found == ops.end()) {
      return caf::make_error(ec::invalid_argument,
                             fmt::format("{} received events for unknown serve "
                                         "id {}",
                                         *self, escape_operator_arg(serve_id)));
    }
    if (found->put_rp.pending()) {
      return caf::make_error(
        ec::logic_error, fmt::format("{} received events for serve id {}, but "
                                     "promise is still pending",
                                     *self, escape_operator_arg(serve_id)));
    }
    found->buffer.push_back(std::move(slice));
    if (not found->get_rps.empty()) {
      const auto delivered = found->try_deliver_results(false);
      if (delivered) {
        TENZIR_DEBUG("{} delivered results eagerly for serve id {}", *self,
                     escape_operator_arg(serve_id));
      }
    }
    if (rows(found->buffer) < std::max(found->requested, found->buffer_size)) {
      return {};
    }
    found->put_rp = self->make_response_promise<void>();
    return found->put_rp;
  }

  auto get(serve_request request)
    -> caf::result<std::tuple<std::string, std::vector<table_slice>>> {
    const auto found
      = std::find_if(ops.begin(), ops.end(), [&](const auto& op) {
          return op.serve_id == request.serve_id;
        });
    if (found == ops.end()) {
      const auto expired_id = expired_ids.find(request.serve_id);
      if (expired_id != expired_ids.end()) {
        if (expired_id->second == ec::diagnostic) {
          return expired_id->second;
        }
        return caf::make_error(
          ec::logic_error,
          fmt::format("{} got request for events with expired serve id {}; the "
                      "pipeline serving this data is no longer available: {}",
                      *self, request.serve_id, expired_id->second));
      }
      return caf::make_error(ec::invalid_argument,
                             fmt::format("{} got request for events with "
                                         "unknown serve id {}",
                                         *self, request.serve_id));
    }
    if (not found->continuation_token.empty()
        and found->last_continuation_token == request.continuation_token) {
      return std::make_tuple(
        found->continuation_token,
        split(found->last_results, request.limits.max_events).first);
    }
    if (found->continuation_token != request.continuation_token) {
      return caf::make_error(
        ec::invalid_argument,
        fmt::format("{} got request for events with unknown continuation token "
                    "{} for serve id {}",
                    *self, request.continuation_token, request.serve_id));
    }
    if (found->done) {
      return std::make_tuple(std::string{}, std::vector<table_slice>{});
    }
    auto rp = self->make_response_promise<
      std::tuple<std::string, std::vector<table_slice>>>();
    found->get_rps.push_back(rp);
    found->requested = request.limits.max_events;
    found->min_events = request.limits.min_events;
    const auto delivered = found->try_deliver_results(false);
    if (delivered) {
      return rp;
    }
    found->delayed_attempt.dispose();
    found->delayed_attempt = detail::weak_run_delayed(
      self, request.limits.timeout,
      [this, serve_id = request.serve_id,
       continuation_token = request.continuation_token]() mutable {
        const auto found
          = std::find_if(ops.begin(), ops.end(), [&](const auto& op) {
              return op.serve_id == serve_id;
            });
        if (found == ops.end()) {
          TENZIR_DEBUG("unable to find serve request after timeout expired");
          return;
        }
        // In case the client re-sent the request in the meantime we are done.
        if (found->done or found->continuation_token != continuation_token) {
          return;
        }
        TENZIR_ASSERT(not found->get_rps.empty());
        const auto delivered = found->try_deliver_results(true);
        TENZIR_ASSERT(delivered);
      });
    return rp;
  }

  auto status(status_verbosity verbosity) const -> caf::result<record> {
    auto requests = list{};
    requests.reserve(ops.size());
    for (const auto& op : ops) {
      auto& entry = as<record>(requests.emplace_back(record{}));
      entry.emplace("serve_id", op.serve_id);
      entry.emplace("continuation_token", op.continuation_token.empty()
                                            ? data{}
                                            : op.continuation_token);
      entry.emplace("buffer_size", op.buffer_size);
      entry.emplace("num_buffered", rows(op.buffer));
      entry.emplace("num_requested", op.requested);
      entry.emplace("num_delivered", op.delivered);
      entry.emplace("lingering", op.continuation_token.empty());
      entry.emplace("done", op.done);
      if (verbosity >= status_verbosity::detailed) {
        entry.emplace("put_pending", op.put_rp.pending());
        entry.emplace("get_pending", not op.get_rps.empty());
        entry.emplace("stop_pending", op.stop_rp.pending());
      }
      if (verbosity >= status_verbosity::debug) {
        entry.emplace("source", fmt::to_string(op.source));
        entry.emplace("last_continuation_token",
                      op.last_continuation_token.empty()
                        ? data{}
                        : op.last_continuation_token);
        entry.emplace("last_num_results", rows(op.last_results));
      }
    }
    return record{
      {"requests", std::move(requests)},
    };
  }
};

auto serve_manager(
  serve_manager_actor::stateful_pointer<serve_manager_state> self)
  -> serve_manager_actor::behavior_type {
  self->state().self = self;
  return {
    [self](atom::start, std::string& serve_id,
           uint64_t buffer_size) -> caf::result<void> {
      return self->state().start(std::move(serve_id), buffer_size);
    },
    [self](atom::stop, std::string& serve_id) -> caf::result<void> {
      return self->state().stop(std::move(serve_id));
    },
    [self](atom::put, std::string& serve_id,
           table_slice& slice) -> caf::result<void> {
      return self->state().put(std::move(serve_id), std::move(slice));
    },
    [self](atom::get, std::string& serve_id, std::string& continuation_token,
           uint64_t min_events, duration timeout, uint64_t max_events)
      -> caf::result<std::tuple<std::string, std::vector<table_slice>>> {
      return self->state().get(
        {.serve_id = std::move(serve_id),
         .continuation_token = std::move(continuation_token),
         .limits = {
           .max_events = max_events,
           .min_events = min_events,
           .timeout = timeout,
         }});
    },
    [self](atom::status, status_verbosity verbosity,
           duration) -> caf::result<record> {
      return self->state().status(verbosity);
    },
  };
}

// -- serve handler -----------------------------------------------------------

using serve_handler_actor
  = typed_actor_fwd<>::extend_with<rest_handler_actor>::unwrap;

struct serve_handler_state {
  static constexpr auto name = "serve-handler";

  serve_handler_actor::pointer self = {};
  serve_manager_actor serve_manager = {};

  struct parse_error {
    std::string message;
    caf::error detail;
  };

  static auto try_parse_request(const tenzir::record& params)
    // TODO: Switch to std::expected<serve_request, parse_error> after C++23.
    -> std::variant<serve_request, parse_error> {
    auto result = serve_request{};
    auto serve_id = try_get<std::string>(params, "serve_id");
    if (not serve_id) {
      return parse_error{
        .message = "failed to read serve_id parameter",
        .detail = caf::make_error(ec::invalid_argument,
                                  fmt::format("{}; got parameters {}",
                                              serve_id.error(), params))};
    }
    if (not*serve_id) {
      return parse_error{
        .message = "serve_id must be specified",
        .detail = caf::make_error(ec::invalid_argument,
                                  fmt::format("got parameters {}", params))};
    }
    result.serve_id = std::move(**serve_id);
    auto continuation_token
      = try_get<std::string>(params, "continuation_token");
    if (not continuation_token) {
      return parse_error{.message = "failed to read continuation_token",
                         .detail = caf::make_error(
                           ec::invalid_argument,
                           fmt::format("{}; got parameters {}",
                                       continuation_token.error(), params))};
    }
    if (*continuation_token) {
      result.continuation_token = std::move(**continuation_token);
    }
    auto max_events = try_get<uint64_t>(params, "max_events");
    if (not max_events) {
      return parse_error{
        .message = "failed to read max_events",
        .detail = caf::make_error(ec::invalid_argument,
                                  fmt::format("parameter: {}; got params {}",
                                              max_events.error(), params))};
    }
    if (*max_events) {
      result.limits.max_events = **max_events;
    }
    auto min_events = try_get<uint64_t>(params, "min_events");
    if (not min_events) {
      return parse_error{
        .message = "failed to read min_events",
        .detail = caf::make_error(ec::invalid_argument,
                                  fmt::format("parameter: {}; got params {}",
                                              max_events.error(), params))};
    }
    if (*min_events) {
      result.limits.min_events = **min_events;
    }
    auto timeout = try_get<duration>(params, "timeout");
    if (not timeout) {
      auto detail_msg
        = fmt::format("{}; got params {}", timeout.error(), params);
      auto detail
        = caf::make_error(ec::invalid_argument, std::move(detail_msg));
      return parse_error{.message = "failed to read timeout parameter",
                         .detail = std::move(detail)};
    }
    if (*timeout) {
      if (**timeout > defaults::api::serve::max_timeout) {
        auto message = fmt::format("timeout exceeds limit of {}",
                                   defaults::api::serve::max_timeout);
        auto detail = caf::make_error(
          ec::invalid_argument, fmt::format("got timeout {}", data{**timeout}));
        return parse_error{.message = std::move(message),
                           .detail = std::move(detail)};
      }
      result.limits.timeout = **timeout;
    }
    auto schema = try_get<std::string>(params, "schema");
    if (not schema) {
      auto detail_msg
        = fmt::format("{}; got params {}", schema.error(), params);
      auto detail
        = caf::make_error(ec::invalid_argument, std::move(detail_msg));
      return parse_error{.message = "failed to read schema parameter",
                         .detail = std::move(detail)};
    }
    if (*schema) {
      auto opt = from_string<enum schema>(**schema);
      if (not opt) {
        return parse_error{
          .message = "invalid schema parameter",
          .detail = caf::make_error(ec::invalid_argument,
                                    fmt::format("got `{}`", **schema))};
      }
      result.schema = *opt;
    }
    return result;
  }

  static auto create_response(const std::string& next_continuation_token,
                              const std::vector<table_slice>& results,
                              serve_state state, enum schema schema)
    -> std::string {
    auto printer = json_printer{{
      .indentation = 0,
      .oneline = true,
      .numeric_durations = true,
    }};
    auto result
      = next_continuation_token.empty()
          ? fmt::format(
              R"({{"next_continuation_token":null,"state":"{}","events":[)",
              state)
          : fmt::format(
              R"({{"next_continuation_token":"{}","state":"{}","events":[)",
              next_continuation_token, state);
    auto out_iter = std::back_inserter(result);
    auto seen_types = std::unordered_set<type>{};
    bool first = true;
    for (const auto& slice : results) {
      if (slice.rows() == 0) {
        continue;
      }
      seen_types.insert(slice.schema());
      auto resolved_slice = resolve_enumerations(slice);
      auto type = as<record_type>(resolved_slice.schema());
      auto array = check(to_record_batch(resolved_slice)->ToStructArray());
      for (const auto& row : values(type, *array)) {
        if (first) {
          out_iter = fmt::format_to(out_iter, "{{");
        } else {
          out_iter = fmt::format_to(out_iter, "}},{{");
        }
        first = false;
        out_iter = fmt::format_to(out_iter, R"("schema_id":"{}","data":)",
                                  slice.schema().make_fingerprint());
        TENZIR_ASSERT(row);
        const auto ok = printer.print(out_iter, *row);
        TENZIR_ASSERT(ok);
      }
    }
    if (schema == schema::never) {
      if (not seen_types.empty()) {
        *out_iter++ = '}';
      }
      *out_iter++ = ']';
      *out_iter++ = '}';
      return result;
    }
    // Write schemas
    if (seen_types.empty()) {
      out_iter = fmt::format_to(out_iter, R"(],"schemas":[]}}{})", '\n');
      return result;
    }
    out_iter = fmt::format_to(out_iter, R"(}}],"schemas":[)");
    for (bool first = true; const auto& type : seen_types) {
      if (first) {
        out_iter = fmt::format_to(out_iter, "{{");
      } else {
        out_iter = fmt::format_to(out_iter, "}},{{");
      }
      first = false;
      out_iter = fmt::format_to(out_iter, R"("schema_id":"{}","definition":)",
                                type.make_fingerprint());
      const auto ok = printer.print(out_iter, schema == schema::legacy
                                                ? type.to_legacy_definition()
                                                : type.to_definition());
      TENZIR_ASSERT(ok);
    }
    out_iter = fmt::format_to(out_iter, R"(}}]}})");
    return result;
  }

  auto http_request(uint64_t endpoint_id, tenzir::record params) const
    -> caf::result<rest_response> {
    if (endpoint_id != SERVE_ENDPOINT_ID) {
      return caf::make_error(ec::logic_error,
                             fmt::format("unepexted /serve endpoint id {}",
                                         endpoint_id));
    }
    TENZIR_DEBUG("{} handles /serve request for endpoint id {} with params {}",
                 *self, endpoint_id, params);
    auto maybe_request = try_parse_request(params);
    if (auto* error = std::get_if<parse_error>(&maybe_request)) {
      return rest_response::make_error(400, std::move(error->message),
                                       std::move(error->detail));
    }
    auto& request = std::get<serve_request>(maybe_request);
    auto rp = self->make_response_promise<rest_response>();
    self
      ->mail(atom::get_v, request.serve_id, request.continuation_token,
             request.limits.min_events, request.limits.timeout,
             request.limits.max_events)
      .request(serve_manager, caf::infinite)
      .then(
        [rp, schema = request.schema](
          const std::tuple<std::string, std::vector<table_slice>>&
            result) mutable {
          const auto& [continuation_token, results] = result;
          rp.deliver(rest_response::from_json_string(
            create_response(continuation_token, results,
                            continuation_token.empty() ? serve_state::completed
                                                       : serve_state::running,
                            schema)));
        },
        [rp, schema = request.schema](const caf::error& err) mutable {
          if (err == caf::exit_reason::user_shutdown
              or err.context().match_elements<diagnostic>()) {
            // The pipeline has either shut down naturally or we got an error
            // that's a diagnostic. In either case, do not report the error as
            // an internal error from the /serve endpoint, but rather report
            // that we're done. The user must get the diagnostic from the
            // `diagnostics` operator.
            rp.deliver(rest_response::from_json_string(create_response(
              {}, {},
              err == caf::exit_reason::user_shutdown ? serve_state::completed
                                                     : serve_state::failed,
              schema)));
            return;
          }
          rp.deliver(rest_response::make_error(400, fmt::to_string(err), {}));
        });
    return rp;
  }
};

auto serve_handler(
  serve_handler_actor::stateful_pointer<serve_handler_state> self,
  const node_actor& node) -> serve_handler_actor::behavior_type {
  self->state().self = self;
  self
    ->mail(atom::get_v, atom::label_v,
           std::vector<std::string>{"serve-manager"})
    .request(node, caf::infinite)
    .await([self](std::vector<caf::actor>& actors) {
      TENZIR_ASSERT(actors.size() == 1);
      self->state().serve_manager
        = caf::actor_cast<serve_manager_actor>(actors.front());
    });
  return {
    [self](atom::http_request, uint64_t endpoint_id,
           tenzir::record& params) -> caf::result<rest_response> {
      return self->state().http_request(endpoint_id, std::move(params));
    },
  };
}

// -- serve operator ----------------------------------------------------------

class serve_operator final : public crtp_operator<serve_operator> {
public:
  serve_operator() = default;

  serve_operator(std::string serve_id, uint64_t buffer_size)
    : serve_id_{std::move(serve_id)}, buffer_size_{buffer_size} {
  }

  auto
  operator()(generator<table_slice> input, operator_control_plane& ctrl) const
    -> generator<std::monostate> {
    auto serve_manager
      = ctrl.self().system().registry().get<serve_manager_actor>(
        "tenzir.serve-manager");
    // Register this operator at SERVE MANAGER actor using the serve_id.
    ctrl.set_waiting(true);
    ctrl.self()
      .mail(atom::start_v, serve_id_, buffer_size_)
      .request(serve_manager, caf::infinite)
      .then(
        [&]() {
          ctrl.set_waiting(false);
          TENZIR_DEBUG("serve for id {} is now available",
                       escape_operator_arg(serve_id_));
        },
        [&](const caf::error& err) { //
          diagnostic::error(err)
            .note("failed to register at serve-manager")
            .emit(ctrl.diagnostics());
        });
    co_yield {};
    // Forward events to the SERVE MANAGER.
    for (auto&& slice : input) {
      if (slice.rows() == 0) {
        co_yield {};
        continue;
      }
      // Send slice to SERVE MANAGER.
      ctrl.set_waiting(true);
      ctrl.self()
        .mail(atom::put_v, serve_id_, std::move(slice))
        .request(serve_manager, caf::infinite)
        .then(
          [&]() {
            ctrl.set_waiting(false);
          },
          [&](const caf::error& err) {
            diagnostic::error(err)
              .note("failed to buffer events at serve-manager")
              .emit(ctrl.diagnostics());
          });
      co_yield {};
    }
    //  Wait until all events were fetched.
    ctrl.set_waiting(true);
    ctrl.self()
      .mail(atom::stop_v, serve_id_)
      .request(serve_manager, caf::infinite)
      .then(
        [&]() {
          ctrl.set_waiting(false);
        },
        [&](const caf::error& err) {
          diagnostic::error(err)
            .note("failed to deregister at serve-manager")
            .emit(ctrl.diagnostics());
        });
    co_yield {};
  }

  auto location() const -> operator_location override {
    return operator_location::remote;
  }

  auto name() const -> std::string override {
    return "serve";
  }

  auto optimize(expression const& filter, event_order order) const
    -> optimize_result override {
    (void)filter, (void)order;
    return do_not_optimize(*this);
  }

  friend auto inspect(auto& f, serve_operator& x) {
    return f.object(x)
      .pretty_name("tenzir.plugins.serve.serve-operator")
      .fields(f.field("serve-id", x.serve_id_),
              f.field("buffer-size", x.buffer_size_));
  }

private:
  std::string serve_id_ = {};
  uint64_t buffer_size_ = {};
};

// -- serve plugin ------------------------------------------------------------

class plugin final : public virtual component_plugin,
                     public virtual rest_endpoint_plugin,
                     public virtual operator_plugin<serve_operator>,
                     public virtual operator_factory_plugin,
                     public virtual aspect_plugin {
public:
  auto component_name() const -> std::string override {
    return "serve-manager";
  }

  auto aspect_name() const -> std::string override {
    return "serves";
  }

  auto show(operator_control_plane& ctrl) const
    -> generator<table_slice> override {
    auto serve_manager = serve_manager_actor{};
    auto blocking = caf::scoped_actor{ctrl.self().system()};
    blocking
      ->mail(atom::get_v, atom::label_v,
             std::vector<std::string>{"serve-manager"})
      .request(ctrl.node(), caf::infinite)
      .receive(
        [&](std::vector<caf::actor>& actors) {
          TENZIR_ASSERT(actors.size() == 1);
          serve_manager
            = caf::actor_cast<serve_manager_actor>(std::move(actors[0]));
        },
        [&](const caf::error& err) { //
          diagnostic::error(err)
            .note("failed to get at serve-manager")
            .emit(ctrl.diagnostics());
        });
    co_yield {};
    auto serves = list{};
    blocking
      ->mail(atom::status_v, status_verbosity::debug,
             duration{std::chrono::seconds{10}})
      .request(serve_manager, caf::infinite)
      .receive(
        [&](record& response) {
          TENZIR_ASSERT(response.size() == 1);
          TENZIR_ASSERT(response.contains("requests"));
          TENZIR_ASSERT(is<list>(response["requests"]));
          serves = std::move(as<list>(response["requests"]));
        },
        [&](const caf::error& err) {
          diagnostic::error(err)
            .note("failed to get status")
            .emit(ctrl.diagnostics());
        });
    co_yield {};
    auto builder = series_builder{};
    for (const auto& serve : serves) {
      builder.data(serve);
    }
    for (auto&& result : builder.finish_as_table_slice("tenzir.serve")) {
      co_yield std::move(result);
    }
  }

  auto make_component(node_actor::stateful_pointer<node_state> node) const
    -> component_plugin_actor override {
    return node->spawn<caf::linked>(serve_manager);
  }

  auto openapi_endpoints(api_version version) const -> record override {
    if (version != api_version::v0) {
      return tenzir::record{};
    }
    auto result = from_yaml(SPEC_V0);
    TENZIR_ASSERT(result, fmt::to_string(result.error()).c_str());
    TENZIR_ASSERT(is<record>(*result));
    return as<record>(*result);
  }

  auto rest_endpoints() const -> const std::vector<rest_endpoint>& override {
    static auto endpoints = std::vector<tenzir::rest_endpoint>{
      {
        .endpoint_id = SERVE_ENDPOINT_ID,
        .method = http_method::post,
        .path = "/serve",
        .params = record_type{
          {"serve_id", string_type{}},
          {"continuation_token", string_type{}},
          {"max_events", uint64_type{}},
          {"min_events", uint64_type{}},
          {"timeout", duration_type{}},
          {"schema", string_type{}},
        },
        .version = api_version::v0,
        .content_type = http_content_type::json,
      },
    };
    return endpoints;
  }

  auto handler(caf::actor_system& system, node_actor node) const
    -> rest_handler_actor override {
    return system.spawn(serve_handler, node);
  }

  auto signature() const -> operator_signature override {
    return {.sink = true};
  }

  auto parse_operator(parser_interface& p) const -> operator_ptr override {
    auto buffer_size
      = located<uint64_t>{defaults::api::serve::max_events, location::unknown};
    auto id = located<std::string>{};
    auto parser = argument_parser{"serve", "https://docs.tenzir.com/"
                                           "operators/serve"};
    parser.add("--buffer-size", buffer_size, "<size>");
    parser.add(id, "<id>");
    parser.parse(p);
    if (id.inner.empty()) {
      diagnostic::error("serve id must not be empty")
        .primary(id.source)
        .throw_();
    }
    if (buffer_size.inner == 0) {
      diagnostic::error("buffer size must not be zero")
        .primary(buffer_size.source)
        .throw_();
    }
    return std::make_unique<serve_operator>(std::move(id.inner),
                                            buffer_size.inner);
  }

  auto make(invocation inv, session ctx) const
    -> failure_or<operator_ptr> override {
    auto id = located<std::string>{};
    auto buffer_size = std::optional<located<uint64_t>>{};
    argument_parser2::operator_("serve")
      .positional("id", id)
      .named("buffer_size", buffer_size)
      .parse(inv, ctx)
      .ignore();
    if (id.inner.empty()) {
      diagnostic::error("serve id must not be empty")
        .primary(id.source)
        .emit(ctx);
    }
    if (buffer_size and buffer_size->inner == 0) {
      diagnostic::error("buffer size must not be zero")
        .primary(buffer_size->source)
        .emit(ctx);
    }
    return std::make_unique<serve_operator>(
      std::move(id.inner),
      buffer_size ? buffer_size->inner : defaults::api::serve::max_events);
  }
};

} // namespace

} // namespace tenzir::plugins::serve

TENZIR_REGISTER_PLUGIN(tenzir::plugins::serve::plugin)
