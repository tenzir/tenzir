#!/usr/bin/env -S uv run --script
# /// script
# dependencies = [
#     "requests",
# ]
# ///

from pathlib import Path
import sys
import textwrap
import typing
import re
from typing import Optional
import contextlib
import itertools
import hashlib
import json

import requests

ALL = object()

# ================== Configuration ================== #
SERVER = "https://schema.ocsf.io"
DOCUMENT_ENTITIES = True
DOCUMENT_FIELDS = False
OCSF_PREFIX = "_ocsf"
OBJECT_INFIX = "object"
COLUMN_LIMIT = 80
EXCLUDE_VERSIONS = ["1.0.0-rc.2", "1.0.0-rc.3"]
ROOT_DIR = Path(__file__).parent.parent
INCLUDE_DIR = ROOT_DIR / "libtenzir/include/tenzir"
SOURCE_DIR = ROOT_DIR / "libtenzir/src"
AUTOGEN_HEADER = "// This file was generated by `ocsf-schemas.py`. Do not edit.\n\n"
# =================================================== #

OMIT_MARKER = object()
BASIC_TYPES = {
    "boolean_t": "bool",
    "float_t": "double",
    "integer_t": "int64",
    "json_t": "null #variant",
    "long_t": "int64",
    "string_t": "string",
    "bytestring_t": "blob",
    "datetime_t": "time",
    "ip_t": "ip",
    "subnet_t": "subnet",
    # TODO: Is this the best choice?
    "timestamp_t": "time",
}

# The schema defines some recursive types which cannot be represented
# faithfully. We generate nonrecursive type variants (with suffix
# "_nonrecursive") that omit these fields, allowing one level of recursion.
# For example, process.parent_process.pid works, but not
# process.parent_process.parent_process.
RECURSIVE_FIELDS: dict[str, dict[str, str]] = {
    # entity name -> (field name -> recursive target entity)
    "ldap_person": {"manager": "user"},
    "process": {"parent_process": "process"},
    "network_proxy": {"proxy_endpoint": "network_proxy"},
    "analytic": {"related_analytics": "analytic"},
    "user": {"ldap_person": "ldap_person"},
}
Schema = dict[str, typing.Any]
TypeMap = dict[str, str]


log_indent = 0


def log(msg: str):
    print(" " * log_indent + "â–¶", msg, file=sys.stderr, flush=True)


@contextlib.contextmanager
def log_section(msg: str):
    global log_indent
    log(msg)
    log_indent += 2
    yield
    log_indent -= 2


def load_schema(version: Optional[str] = None) -> Schema:
    url = SERVER
    if version is not None:
        url += "/" + version
    url += "/export/schema"
    log(f"Fetching schema from {url}")
    for _ in range(5):
        try:
            return requests.get(url, timeout=5).json()
        except requests.exceptions.ConnectTimeout:
            pass
    raise TimeoutError


def patch_types(schema: Schema) -> None:
    log("Patching types")
    types = {}
    for type_name, type_def in schema["types"].items():
        if type_name in BASIC_TYPES:
            result = BASIC_TYPES[type_name]
        else:
            result = type_def["type"]
            if result in BASIC_TYPES:
                result = BASIC_TYPES[result]
        types[type_name] = result
    schema["types"] = types


def mangle_version(version: str) -> str:
    version = "v" + version.replace(".", "_").replace("-", "_")
    return re.sub("[^0-9a-zA-Z_]", "", version)


def class_prefix(schema: Schema) -> str:
    return OCSF_PREFIX + "." + mangle_version(schema["version"])


def object_prefix(schema: Schema) -> str:
    return class_prefix(schema) + "." + "object"


def hash_enum(enum: dict[int, dict]) -> str:
    pairs = []
    for num, info in sorted(enum.items()):
        pairs.append((num, info["caption"]))
    return hashlib.sha1(json.dumps(pairs).encode()).hexdigest()[:8]


class Writer:
    def __init__(self, file: typing.TextIO):
        self.file = file
        self.indent = 0

    def print(self, *args, **kwargs) -> None:
        print(self.indent * " ", file=self.file, end="")
        print(*args, **kwargs, file=self.file)

    def comment(self, text: str) -> None:
        width = COLUMN_LIMIT - self.indent - len("// ")
        lines = textwrap.wrap(text, width)
        for line in lines:
            self.print("//", line)

    def begin(self, *args, **kwargs) -> None:
        self.print(*args, **kwargs)
        self.indent += 2

    def end(self, *args, **kwargs) -> None:
        self.indent -= 2
        if self.indent < 0:
            raise ValueError
        self.print(*args, **kwargs)


def _emit_entity(
    writer: Writer,
    schema: Schema,
    entity: dict,
    entity_name: str,
    objects: bool,
    *,
    type_suffix: str = "",
    skip_fields: typing.Iterable[str] = (),
    resolve_recursive_fields: bool = False,
) -> None:
    """Emit a single entity type definition.

    Args:
        writer: Writer to output to
        schema: OCSF schema
        entity: Entity definition
        entity_name: Name of the entity
        objects: True if emitting objects, False if emitting classes
        type_suffix: Suffix to add to type name (e.g., "_nonrecursive")
        skip_fields: List of field names to skip
        resolve_recursive_fields: If True, resolve recursive fields to _nonrecursive variants
    """
    prefix = object_prefix(schema) if objects else class_prefix(schema)
    types = schema["types"]
    full_name = f"{prefix}.{entity_name}{type_suffix}"
    recursive_fields = RECURSIVE_FIELDS.get(entity_name, {})
    skip_fields = set(skip_fields)

    writer.begin(f"type {full_name} = record{{")
    for attr_name, attr_def in sorted(entity["attributes"].items()):
        if attr_name in skip_fields:
            continue
        profile = attr_def.get("profile")
        if "object_type" in attr_def:
            type_name = attr_def["object_type"]
            # Special-case the "Object" type to use a JSON string instead.
            if type_name == "object":
                resolved = "null #variant #must_be_record"
            else:
                # Ignore the extension written before the slash.
                slash = type_name.find("/")
                if slash != -1:
                    type_name = type_name[slash + 1 :]
                resolved = f"{object_prefix(schema)}.{type_name}"
                if resolve_recursive_fields and attr_name in recursive_fields:
                    target = recursive_fields[attr_name]
                    resolved = f"{object_prefix(schema)}.{target}_nonrecursive"
        else:
            resolved = types[attr_def["type"]]
            if resolved is OMIT_MARKER:
                continue
        if attr_def.get("is_array", False):
            resolved = f"list<{resolved}>"
        if DOCUMENT_FIELDS:
            writer.comment(attr_def["description"])
        requirement = attr_def["requirement"]
        attributes = f" #{requirement}"
        if profile is not None:
            attributes += f" #profile={profile}"
        extension = attr_def.get("extension")
        if extension is not None:
            attributes += f" #extension={extension}"
        if not objects and attr_name == "unmapped":
            attributes += " #nullify_empty_records"
        if "enum" in attr_def:
            sibling = attr_def.get("sibling")
            if sibling is None:
                log(
                    f"Warning: Enum {attr_name} of {entity_name} doesn't have sibling"
                )
            else:
                attributes += f" #enum={hash_enum(attr_def["enum"])}"
                attributes += f" #sibling={sibling}"
        writer.print(f"{attr_name}: {resolved}{attributes},")
    attributes = ""
    if extension := entity.get("extension"):
        attributes += f" #extension={extension}"
    writer.end(f"}}{attributes}")


def _emit(writer: Writer, schema: Schema, *, objects: bool) -> None:
    name = "objects" if objects else "classes"
    types = schema["types"]
    first = True
    for _, entity in sorted(schema[name].items()):
        # For classes, we do not use the given entity name, but instead derive
        # the name from the caption. This is due to classes such as "Device
        # Inventory Info", which have a name "inventory_info", which makes the
        # name hard to predict from the class name, or even misspelled ones.
        if objects:
            entity_name = entity["name"]
        else:
            entity_name = entity["caption"].lower().replace(" ", "_")

        # Skip special case
        prefix = object_prefix(schema) if objects else class_prefix(schema)
        if f"{prefix}.{entity_name}" == "ocsf.object.object":
            # Not needed because this is special-case to print JSON.
            continue

        recursive_fields = RECURSIVE_FIELDS.get(entity_name, {})

        # Emit nonrecursive variant first if this entity has recursive fields
        if recursive_fields:
            if not first:
                writer.print()
            first = False
            if DOCUMENT_ENTITIES:
                writer.comment(entity["description"])
            _emit_entity(
                writer,
                schema,
                entity,
                entity_name,
                objects,
                type_suffix="_nonrecursive",
                skip_fields=recursive_fields.keys(),
                resolve_recursive_fields=False,
            )

        # Emit main type
        if not first:
            writer.print()
        first = False
        if DOCUMENT_ENTITIES:
            writer.comment(entity["description"])
        _emit_entity(
            writer,
            schema,
            entity,
            entity_name,
            objects,
            type_suffix="",
            skip_fields=[],
            resolve_recursive_fields=True,
        )


def emit_classes(writer: Writer, schema: Schema) -> None:
    _emit(writer, schema, objects=False)


def emit_objects(writer: Writer, schema: Schema) -> None:
    _emit(writer, schema, objects=True)


def ocsf_schema_dir() -> Path:
    types = ROOT_DIR / "schema/types"
    if not types.is_dir():
        raise NotADirectoryError(f"expected {types} to be a directory")
    ocsf_dir = types / "ocsf"
    ocsf_dir.mkdir(exist_ok=True)
    return ocsf_dir


def open_schema_file(version: str):
    name = mangle_version(version) + ".schema"
    path = ocsf_schema_dir() / name
    log(f"Writing schema file {path}")
    return path.open("w")


def collect_enum(schema: Schema, attribute: str) -> dict[int, str]:
    result = {}
    for entity in schema["classes"].values():
        enum = entity["attributes"][attribute]["enum"]
        for key, value in enum.items():
            num = int(key)
            name = value["caption"]
            if num in result:
                if result[num] != name:
                    log(
                        f"WARNING: Got mismatch {repr(result[num])} vs {repr(name)} for {num}"
                    )
            result[num] = name
    return dict(sorted(result.items()))


def write_enum(schemas: list[Schema], attribute: str, filename: str) -> None:
    enum_inc = INCLUDE_DIR / filename
    log(f"Writing {enum_inc}")
    with enum_inc.open("w") as f:
        f.write(AUTOGEN_HEADER)
        for schema in schemas:
            enum_values = collect_enum(schema, attribute)
            for num, name in sorted(enum_values.items()):
                f.write(f'X({mangle_version(schema["version"])}, {num}, "{name}")\n')


def write_generic_enums(schemas: list[Schema]) -> None:
    table = {}
    for schema in schemas:
        entities = itertools.chain(
            schema["classes"].values(), schema["objects"].values()
        )
        for entity in entities:
            for attr_name, attr_def in entity["attributes"].items():
                enum = attr_def.get("enum")
                if enum is None:
                    continue
                hashed = hash_enum(enum)
                if hashed in table:
                    continue
                try:
                    values = {int(x): y["caption"] for x, y in enum.items()}
                    table[hashed] = values
                except ValueError:
                    log(f"Warning: Found invalid enum definition: {attr_name}")
    enum_inc = INCLUDE_DIR / "ocsf_enums.inc"
    log(f"Writing {enum_inc}")
    with enum_inc.open("w") as f:
        f.write(AUTOGEN_HEADER)
        f.write("{\n")
        for hashed, values in sorted(table.items()):
            f.write(f'  {{"{hashed}", {{\n')
            for num, caption in sorted(values.items()):
                f.write(f'    {{{num}, "{caption}"}},\n')
            f.write("  }},\n")
        f.write("}\n")


def write_enums(schemas: list[Schema]) -> None:
    write_generic_enums(schemas)
    with log_section("Collecting fundamental enum files"):
        write_enum(schemas, "category_uid", "ocsf_categories.inc")
        write_enum(schemas, "class_uid", "ocsf_classes.inc")
        write_enum(schemas, "type_uid", "ocsf_types.inc")


def write_versions(schemas: list[Schema]) -> None:
    path = INCLUDE_DIR / "ocsf_versions.inc"
    log(f"Writing {path}")
    with path.open("w") as f:
        f.write(AUTOGEN_HEADER)
        for schema in schemas:
            version = schema["version"]
            f.write(f'X("{version}", {mangle_version(version)})\n')


def fetch_versions() -> list[str]:
    log(f"Fetching available versions from {SERVER}")
    body = requests.get(SERVER).content.decode()
    return sorted(
        version
        for version in re.findall("<option value=[^>]*>v([^<]*)</option>", body)
        if version not in EXCLUDE_VERSIONS
    )


def delete_schemas() -> None:
    directory = ocsf_schema_dir()
    log(f"Deleting schemas in {directory}")
    for path in directory.glob("*.schema"):
        path.unlink()


def main():
    versions = fetch_versions()
    delete_schemas()
    schemas = []
    for version in versions:
        with log_section(f"Processing version {version}"):
            schema = load_schema(version)
            patch_types(schema)
            with open_schema_file(version) as f:
                writer = Writer(f)
                writer.comment("This file is generated, do not edit manually.")
                writer.comment(f"OCSF version: {version}")
                writer.print()
                emit_objects(writer, schema)
                writer.print()
                emit_classes(writer, schema)
            schemas.append(schema)
    write_versions(schemas)
    write_enums(schemas)
    log("Done")


if __name__ == "__main__":
    main()
