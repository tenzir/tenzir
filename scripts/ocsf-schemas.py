#!/usr/bin/env python3

from pathlib import Path
import sys
import textwrap
import typing
import re
from typing import Optional
import contextlib

import requests

ALL = object()

# ================== Configuration ================== #
SERVER = "https://schema.ocsf.io"
DOCUMENT_ENTITIES = True
DOCUMENT_FIELDS = False
OCSF_PREFIX = "_ocsf"
OBJECT_INFIX = "object"
COLUMN_LIMIT = 80
EXCLUDE_VERSIONS = ["1.0.0-rc.2", "1.0.0-rc.3"]
ROOT_DIR = Path(__file__).parent.parent
INCLUDE_DIR = ROOT_DIR / "libtenzir/include/tenzir"
AUTOGEN_HEADER = "// This file was generated by `ocsf-schemas.py`. Do not edit.\n\n"
# =================================================== #

OMIT_MARKER = object()
BASIC_TYPES = {
    "boolean_t": "bool",
    "float_t": "double",
    "integer_t": "int64",
    "json_t": "string #print_json",
    "long_t": "int64",
    "string_t": "string",
    "bytestring_t": "blob",
    "datetime_t": "time",
    "ip_t": "ip",
    "subnet_t": "subnet",
    # TODO: Is this the best choice?
    "timestamp_t": "time",
}

# TODO: The schema defines some recursive types which cannot be represented
# faithfully. Hence, we omit some fields to break recursive cycles. Instead of
# that, we could recursively unfold the types up to a certain depth, or perhaps
# use a slightly different representation.
OMIT = {
    "ldap_person": ["manager"],
    "process": ["parent_process"],
    "network_proxy": ["proxy_endpoint"],
    "analytic": ["related_analytics"],
}
Schema = dict[str, dict]
TypeMap = dict[str, str]


log_indent = 0


def log(msg: str):
    print(" " * log_indent + "â–¶", msg, file=sys.stderr, flush=True)


@contextlib.contextmanager
def log_section(msg: str):
    global log_indent
    log(msg)
    log_indent += 2
    yield
    log_indent -= 2


def load_schema(version: Optional[str] = None) -> Schema:
    url = SERVER
    if version is not None:
        url += "/" + version
    url += "/export/schema"
    log(f"Fetching schema from {url}")
    return requests.get(url).json()


def patch_types(schema: Schema) -> None:
    log("Patching types")
    types = {}
    for type_name, type_def in schema["types"].items():
        if type_name in BASIC_TYPES:
            result = BASIC_TYPES[type_name]
        else:
            result = type_def["type"]
            if result in BASIC_TYPES:
                result = BASIC_TYPES[result]
        types[type_name] = result
    schema["types"] = types


def mangle_version(version: str) -> str:
    version = "v" + version.replace(".", "_").replace("-", "_")
    return re.sub("[^0-9a-zA-Z_]", "", version)


def class_prefix(schema: Schema) -> str:
    return OCSF_PREFIX + "." + mangle_version(schema["version"])


def object_prefix(schema: Schema) -> str:
    return class_prefix(schema) + "." + "object"


class Writer:
    def __init__(self, file: typing.TextIO):
        self.file = file
        self.indent = 0

    def print(self, *args, **kwargs) -> None:
        print(self.indent * " ", file=self.file, end="")
        print(*args, **kwargs, file=self.file)

    def comment(self, text: str) -> None:
        width = COLUMN_LIMIT - self.indent - len("// ")
        lines = textwrap.wrap(text, width)
        for line in lines:
            self.print("//", line)

    def begin(self, *args, **kwargs) -> None:
        self.print(*args, **kwargs)
        self.indent += 2

    def end(self, *args, **kwargs) -> None:
        self.indent -= 2
        if self.indent < 0:
            raise ValueError
        self.print(*args, **kwargs)


def _emit(writer: Writer, schema: Schema, *, objects: bool) -> None:
    name = "objects" if objects else "classes"
    prefix = object_prefix(schema) if objects else class_prefix(schema)
    types = schema["types"]
    first = True
    for entity in schema[name].values():
        if not first:
            writer.print()
        first = False
        if DOCUMENT_ENTITIES:
            writer.comment(entity["description"])
        # For classes, we do not use the given entity name, but instead derive
        # the name from the caption. This is due to classes such as "Device
        # Inventory Info", which have a name "inventory_info", which makes the
        # name hard to predict from the class name, or even misspelled ones.
        if objects:
            entity_name = entity["name"]
        else:
            entity_name = entity["caption"].lower().replace(" ", "_")
        full_name = f"{prefix}.{entity_name}"
        if full_name == "ocsf.object.object":
            # Not needed because this is special-case to print JSON.
            continue
        omit = OMIT.get(entity_name, [])
        writer.begin(f"type {full_name} = record{{")
        for attr_name, attr_def in sorted(entity["attributes"].items()):
            if attr_name in omit:
                continue
            profile = attr_def.get("profile")
            if "object_type" in attr_def:
                type_name = attr_def["object_type"]
                # Special-case the "Object" type to use a JSON string instead.
                if type_name == "object":
                    resolved = "string #print_json #must_be_record"
                else:
                    # Ignore the extension written before the slash.
                    slash = type_name.find("/")
                    if slash != -1:
                        type_name = type_name[slash + 1 :]
                    resolved = f"{object_prefix(schema)}.{type_name}"
            else:
                resolved = types[attr_def["type"]]
                if resolved is OMIT_MARKER:
                    continue
            if attr_def.get("is_array", False):
                resolved = f"list<{resolved}>"
            if DOCUMENT_FIELDS:
                writer.comment(attr_def["description"])
            requirement = attr_def["requirement"]
            attributes = f" #{requirement}"
            if profile is not None:
                attributes += f" #profile={profile}"
            extension = attr_def.get("extension")
            if extension is not None:
                attributes += f" #extension={extension}"
            if not objects and attr_name == "unmapped":
                attributes += " #nullify_empty_records"
            writer.print(f"{attr_name}: {resolved}{attributes},")
        attributes = ""
        if extension := entity.get("extension"):
            attributes += f" #extension={extension}"
        writer.end(f"}}{attributes}")


def emit_classes(writer: Writer, schema: Schema) -> None:
    _emit(writer, schema, objects=False)


def emit_objects(writer: Writer, schema: Schema) -> None:
    _emit(writer, schema, objects=True)


def ocsf_schema_dir() -> Path:
    types = ROOT_DIR / "schema/types"
    if not types.is_dir():
        raise NotADirectoryError(f"expected {types} to be a directory")
    ocsf_dir = types / "ocsf"
    ocsf_dir.mkdir(exist_ok=True)
    return ocsf_dir


def open_schema_file(version: str):
    name = mangle_version(version) + ".schema"
    path = ocsf_schema_dir() / name
    log(f"Writing schema file {path}")
    return path.open("w")


def collect_enum(schema: Schema, attribute: str) -> dict[int, str]:
    result = {}
    for entity in schema["classes"].values():
        enum = entity["attributes"][attribute]["enum"]
        for key, value in enum.items():
            num = int(key)
            name = value["caption"]
            if num in result:
                if result[num] != name:
                    log(
                        f"WARNING: Got mismatch {repr(result[num])} vs {repr(name)} for {num}"
                    )
            result[num] = name
    return dict(sorted(result.items()))


def write_enum(schemas: list[Schema], attribute: str, filename: str) -> None:
    enum_inc = INCLUDE_DIR / filename
    log(f"Writing {enum_inc}")
    with enum_inc.open("w") as f:
        f.write(AUTOGEN_HEADER)
        for schema in schemas:
            enum_values = collect_enum(schema, attribute)
            for num, name in sorted(enum_values.items()):
                f.write(f'X({mangle_version(schema["version"])}, {num}, "{name}")\n')


def write_enums(schemas: list[Schema]):
    with log_section("Collecting and writing enum files"):
        write_enum(schemas, "category_uid", "ocsf_categories.inc")
        write_enum(schemas, "class_uid", "ocsf_classes.inc")
        write_enum(schemas, "type_uid", "ocsf_types.inc")


def write_versions(schemas: list[Schema]) -> None:
    path = INCLUDE_DIR / "ocsf_versions.inc"
    log(f"Writing {path}")
    with path.open("w") as f:
        f.write(AUTOGEN_HEADER)
        for schema in schemas:
            version = schema["version"]
            f.write(f'X("{version}", {mangle_version(version)})\n')


def fetch_versions() -> list[str]:
    log(f"Fetching available versions from {SERVER}")
    body = requests.get(SERVER).content.decode()
    return [
        version
        for version in re.findall("<option value=[^>]*>v([^<]*)</option>", body)
        if version not in EXCLUDE_VERSIONS
    ]


def delete_schemas() -> None:
    directory = ocsf_schema_dir()
    log(f"Deleting schemas in {directory}")
    for path in directory.glob("*.schema"):
        path.unlink()


def main():
    versions = fetch_versions()
    delete_schemas()
    schemas = []
    for version in versions:
        with log_section(f"Processing version {version}"):
            schema = load_schema(version)
            patch_types(schema)
            with open_schema_file(version) as f:
                writer = Writer(f)
                writer.comment("This file is generated, do not edit manually.")
                writer.comment(f"OCSF version: {version}")
                writer.print()
                emit_objects(writer, schema)
                writer.print()
                emit_classes(writer, schema)
            schemas.append(schema)
    write_versions(schemas)
    write_enums(schemas)
    log("Done")


if __name__ == "__main__":
    main()
