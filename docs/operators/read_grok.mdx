---
title: read_grok
category: Parsing
example: 'read_grok "%{IP:client} %{WORD:action}"'
---

Parses lines of input with a grok pattern.

```tql
read_grok pattern:string, [pattern_definitions=record|string, indexed_captures=bool,
          include_unnamed=bool, schema=string, selector=string,
          schema_only=bool, merge=bool, raw=bool, unflatten_separator=string]
```

## Description

`read_grok` uses a regular expression based parser similar to the
[Logstash `grok` plugin](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)
in Elasticsearch. Tenzir ships with the same built-in patterns as Elasticsearch,
found [here](https://github.com/logstash-plugins/logstash-patterns-core/tree/main/patterns/ecs-v1).

In short, `pattern` consists of replacement fields, that look like
`%{SYNTAX[:SEMANTIC[:CONVERSION]]}`, where:
- `SYNTAX` is a reference to a pattern, either built-in or user-defined
    through the `pattern_defintions` option.
- `SEMANTIC` is an identifier that names the field in the parsed record.
- `CONVERSION` is either `infer` (default), `string` (default with
    `raw=true`), `int`, or `float`.

The supported regular expression syntax is the one supported by
[Boost.Regex](https://www.boost.org/doc/libs/1_81_0/libs/regex/doc/html/boost_regex/syntax/perl_syntax.html),
which is effectively Perl-compatible.

### `pattern: string`

The `grok` pattern used for matching. Must match the input in its entirety.

### `pattern_definitions = record|string (optional)`

New pattern definitions to use. This may be a record of the form

```tql
{
  pattern_name: "pattern"
}
```

For example, the built-in pattern `INT` would be defined as

```tql
{ INT: "(?:[+-]?(?:[0-9]+))" }
```

Alternatively, this may be a user-defined newline-delimited list of patterns,
where a line starts with the pattern name, followed by a space, and the
`grok`-pattern for that pattern. For example, the built-in pattern `INT` is
defined as follows:

```
INT (?:[+-]?(?:[0-9]+))
```

### `indexed_captures = bool (optional)`

All subexpression captures are included in the output, with the `SEMANTIC` used
as the field name if possible, and the capture index otherwise.

### `include_unnamed = bool (optional)`

By default, only fields that were given a name with `SEMANTIC`, or with
the regular expression named capture syntax `(?<name>...)` are included
in the resulting record.

With `include_unnamed=true`, replacement fields without a `SEMANTIC` are included
in the output, using their `SYNTAX` value as the record field name.

import ParsingOptions from '../../.../../../../partials/operators/ParsingOptions.mdx';

<ParsingOptions />

## Examples

### Parse a fictional HTTP request log

```tql
// Input: 55.3.244.1 GET /index.html 15824 0.043
let $pattern = "%{IP:client} %{WORD} %{URIPATHPARAM:req} %{NUMBER:bytes} %{NUMBER:dur}"
read_grok $pattern
```
```tql
{
  client: 55.3.244.1,
  req: "/index.html",
  bytes: 15824,
  dur: 0.043
}
```

## See Also

[`parse_grok`](/reference/functions/parse_grok)
